{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# R Code"
      ],
      "metadata": {
        "id": "RltfWLp-RPR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "fwFPIBTeRMcS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l29dkCGOt152"
      },
      "outputs": [],
      "source": [
        "!pip install rpy2==3.5.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext rpy2.ipython"
      ],
      "metadata": {
        "id": "drFVj_-8uL0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "## Install packages needed\n",
        "install.packages(\"data.table\")\n",
        "install.packages(\"jsonlite\")\n",
        "install.packages(\"stringr\")\n",
        "install.packages(\"dplyr\")\n",
        "install.packages(\"magrittr\")\n",
        "install.packages(\"gutenbergr\")\n",
        "install.packages(\"textdata\")\n",
        "install.packages(\"tm\")\n",
        "install.packages(\"tidytext\")\n",
        "install.packages(\"janeaustenr\")\n",
        "install.packages(\"ggplot2\")"
      ],
      "metadata": {
        "id": "mps3AHc1uPs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "## Load packages needed\n",
        "require(data.table)\n",
        "require(jsonlite)\n",
        "require(stringr)\n",
        "require(magrittr)\n",
        "require(dplyr)\n",
        "require(gutenbergr)\n",
        "require(textdata)\n",
        "require(tm)\n",
        "require(tidytext)\n",
        "require(janeaustenr)\n",
        "require(ggplot2)"
      ],
      "metadata": {
        "id": "wM-LlRgMuTc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Formats"
      ],
      "metadata": {
        "id": "5Hr_bWOeuiKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector"
      ],
      "metadata": {
        "id": "kE5HmL_bvimQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#### Vector ####\n",
        "\n",
        "# Setting up a simple example dataset\n",
        "text_df <- data.frame(doc=c(1, 2, 3),\n",
        "                      text=c(\"Welcome to the RPM meeting\",\n",
        "                             \"In this session we are covering text mining\",\n",
        "                             \"By the end you'll be familiar with the basics of the tidytext package\")\n",
        "                      )\n",
        "text_df\n"
      ],
      "metadata": {
        "id": "0a4KyJWNudSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Our text is a vector\n",
        "text_df$text\n"
      ],
      "metadata": {
        "id": "aATHplz5vmzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Corpus"
      ],
      "metadata": {
        "id": "S0K3lEBzvo7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#### Corpus ####\n",
        "\n",
        "# We can convert our text vector to a corpus using functions from the tm package\n",
        "text_corpus <- VCorpus(VectorSource(text_df$text))\n",
        "text_corpus\n"
      ],
      "metadata": {
        "id": "cqjo16HguzTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "text_corpus[[1]] # View first document"
      ],
      "metadata": {
        "id": "pwHfOahMvt5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "text_corpus[[1]]$meta # View metadata for first document"
      ],
      "metadata": {
        "id": "brFnkrr0vwZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "text_corpus[[1]]$content # View content for first document"
      ],
      "metadata": {
        "id": "LtjK_KA2vyxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# An example corpus of Reuters news articles from the tm package\n",
        "data(acq)\n",
        "acq"
      ],
      "metadata": {
        "id": "KtGR8UoOv3yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "acq[[1]]$meta # View metadata for first document"
      ],
      "metadata": {
        "id": "K9pQhRf8v5Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "acq[[1]]$content # View content for first document"
      ],
      "metadata": {
        "id": "2VTr4roIv7e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# We can apply functions to documents within a corpus to clean up the text for analysis:\n",
        "acq_lower <- tm_map(acq, content_transformer(tolower))\n",
        "\n",
        "#Compare first document before...\n",
        "acq[[1]]$content"
      ],
      "metadata": {
        "id": "nW1LHbJPv_dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# ... and after\n",
        "acq_lower[[1]]$content"
      ],
      "metadata": {
        "id": "n57LWh9IwERl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Document Term Matrix"
      ],
      "metadata": {
        "id": "7Zcc6gQ5wNvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#### DTM ####\n",
        "\n",
        "# Convert our corpus into a DTM\n",
        "text_dtm <- DocumentTermMatrix(text_corpus)\n",
        "inspect(text_dtm)\n"
      ],
      "metadata": {
        "id": "evlLwfd4vZCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tidy"
      ],
      "metadata": {
        "id": "d-scXrYlwUjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#### Tidy ####\n",
        "\n",
        "# Convert our dataframe into a tidy data frame\n",
        "# https://www.rdocumentation.org/packages/tidytext/versions/0.4.1/topics/unnest_tokens\n",
        "text_tidy <- text_df %>%\n",
        "  unnest_tokens(word, text)\n",
        "text_tidy\n"
      ],
      "metadata": {
        "id": "0rP1PQ9MwTq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting between formats"
      ],
      "metadata": {
        "id": "sIUsjwc7xXbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Above we showed vector->corpus, corpus->DTM, vector->tidy\n",
        "\n",
        "# To convert from corpus -> vector/dataframe we can use the tidy function\n",
        "text_corpus_df <- text_corpus %>%\n",
        "  tidy()\n",
        "text_corpus_df"
      ],
      "metadata": {
        "id": "r6UxGkSfxagt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Since we now have metadata that we don't need for now, we can remove. Also, convert to dataframe instead of tibble\n",
        "text_corpus_df <- text_corpus_df %>%\n",
        "  select(id, text) %>%\n",
        "  as.data.frame\n",
        "text_corpus_df"
      ],
      "metadata": {
        "id": "aQjloF0cxluL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# We can now convert this to tidytext (so for corpus -> tidy, we do corpus -> df -> tidy)\n",
        "text_corpus_tidy <- text_corpus_df %>%\n",
        "  unnest_tokens(word, text)\n",
        "text_corpus_tidy"
      ],
      "metadata": {
        "id": "d3UyYOoUy4dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# To convert from tidy->DTM, we need to first summarize the tidytext data\n",
        "text_summarized <- text_tidy %>%\n",
        "  count(doc, word, sort = FALSE)\n",
        "text_summarized"
      ],
      "metadata": {
        "id": "iRiZ_Vu2y9OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "## The summarized table can be cast to DTM\n",
        "text_tidy_dtm <- text_summarized %>%\n",
        "  cast_dtm(document=doc, term=word, value=n)\n",
        "inspect(text_tidy_dtm)"
      ],
      "metadata": {
        "id": "nYyrODdmzHsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# We can check the unique terms in our matrix\n",
        "Terms(text_tidy_dtm)"
      ],
      "metadata": {
        "id": "7Os8Oz5jzgHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# To convert from DTM->tidy, we can again use the tidy function (note this drops\n",
        "# words less than 2 characters long)\n",
        "text_dtm_tidy <- tidy(text_dtm)\n",
        "text_dtm_tidy\n"
      ],
      "metadata": {
        "id": "nb8c7l8M0Kc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Jane Austen data"
      ],
      "metadata": {
        "id": "xPMBVlJ-45pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Reading in Jane Austen books from janeaustenr package\n",
        "\n",
        "austen_books()\n",
        "tidy_books <- austen_books() %>%\n",
        "  group_by(book) %>%\n",
        "  mutate(linenumber = row_number(),\n",
        "         # Divide into chapters by searching for instances of 'Chapter X'\n",
        "         chapter = cumsum(str_detect(text, regex(\"^chapter [\\\\divxlc]\",ignore_case = TRUE)))) %>%\n",
        "  ungroup() %>%\n",
        "  unnest_tokens(word, text)\n",
        "tidy_books\n"
      ],
      "metadata": {
        "id": "djhmvyn_4_B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Term Frequency"
      ],
      "metadata": {
        "id": "ifBDT0Tq5N5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Calculate the word frequency by novel and sort by most common words\n",
        "book_words <- tidy_books %>%\n",
        "  count(book, word, sort = TRUE)\n",
        "book_words\n"
      ],
      "metadata": {
        "id": "iX6W0Xdx5Eg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# We saw common words that aren't very meaningful in analyzing text, like 'the'. We can remove a list of these \"stop words\"\n",
        "data(stop_words)\n",
        "\n",
        "tidy_books <- tidy_books %>%\n",
        "  anti_join(stop_words)\n",
        "\n",
        "stop_words"
      ],
      "metadata": {
        "id": "raDJi1Eh5Rwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Try term frequency again\n",
        "book_words <- tidy_books %>%\n",
        "  count(book, word, sort = TRUE)\n",
        "book_words\n"
      ],
      "metadata": {
        "id": "7PjOql7k5WF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Check top words for Mansfield Park\n",
        "book_words %>% filter(book == \"Mansfield Park\")"
      ],
      "metadata": {
        "id": "4ORePrjZ5tpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Check top words for Emma\n",
        "book_words %>% filter(book == \"Emma\")"
      ],
      "metadata": {
        "id": "9Ltiegmd50yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# We can calculate the total number of words in each novel and join\n",
        "total_words <- book_words %>% \n",
        "  group_by(book) %>% \n",
        "  summarize(total = sum(n))\n",
        "book_words <- left_join(book_words, total_words)\n",
        "book_words\n"
      ],
      "metadata": {
        "id": "KhPel9Jh55e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Now we can calculate the frequency of each word in each novel as a percentage\n",
        "freq <- book_words %>% \n",
        "  group_by(book) %>% \n",
        "  mutate(term_frequency = n/total) %>%\n",
        "  ungroup()\n",
        "freq\n"
      ],
      "metadata": {
        "id": "2fGU1Gmz6HQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# We can use bind_tf_idf to calculate the tf_idf, which will give a better measure of the importance of each word\n",
        "book_tf_idf <- book_words %>%\n",
        "  bind_tf_idf(word, book, n)\n",
        "book_tf_idf\n"
      ],
      "metadata": {
        "id": "mWQr30Ug6N2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Sorting by the TF IDF can help us identify words that most distinguish a document.\n",
        "# In this case, they are all characters that are unique to each book, which\n",
        "# makes a lot of sense.\n",
        "book_tf_idf %>% arrange(-tf_idf)"
      ],
      "metadata": {
        "id": "0fPDF7kt6abD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis"
      ],
      "metadata": {
        "id": "K8ElurVIQXcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Tidytext includes multiple sentiment dictionaries. We'll use the AFINN, which scores sentiment on -5 (negative) to +5 (positive)\n",
        "\n",
        "afinn <- get_sentiments(\"afinn\")\n"
      ],
      "metadata": {
        "id": "mfqPsAudQaiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Now, we will attach sentiments using inner_join (words with no sentiment in the dictionary would be dropped)\n",
        "jane_austen_sentiment <- tidy_books %>% \n",
        "  inner_join(afinn)\n",
        "jane_austen_sentiment\n"
      ],
      "metadata": {
        "id": "wfi5o5mTQczw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Let's see which words in Pride & Prejudice are the most positive\n",
        "most_positive <- jane_austen_sentiment %>%\n",
        "  filter(book == \"Pride & Prejudice\") %>%\n",
        "  arrange(-value) %>%\n",
        "  head(10)\n",
        "most_positive"
      ],
      "metadata": {
        "id": "n9fns5ZwRXdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Now what about the most negative words?\n",
        "most_negative <- jane_austen_sentiment %>%\n",
        "  filter(book == \"Pride & Prejudice\") %>%\n",
        "  arrange(value) %>%\n",
        "  head(10)\n",
        "most_negative"
      ],
      "metadata": {
        "id": "ZVCUynkASB-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Summarize to 80 line chunks, summing the sentiment scores\n",
        "jane_austen_sentiment_summarized <- jane_austen_sentiment %>% \n",
        "  group_by(book, index = linenumber %/% 80) %>% \n",
        "  summarise(sentiment = sum(value))\n",
        "jane_austen_sentiment_summarized\n"
      ],
      "metadata": {
        "id": "yM98CRFSQkDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# Now we can plot sentiment score chronologically across the novels\n",
        "ggplot(jane_austen_sentiment_summarized, aes(index, sentiment, fill = book)) +\n",
        "  geom_col(show.legend = FALSE) +\n",
        "  facet_wrap(~book, ncol = 2, scales = \"free_x\")\n"
      ],
      "metadata": {
        "id": "5TfpjOZlQsKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}